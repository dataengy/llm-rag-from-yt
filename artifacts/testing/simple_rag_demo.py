#!/usr/bin/env python3
"""Simple RAG demo using project dependencies."""

import os
import sys
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime

from loguru import logger as log
from bash import bash

# Add src to Python path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

# Setup detailed logging
log_dir = Path(__file__).parent.parent.parent / "logs"
log_dir.mkdir(exist_ok=True)

log_file = log_dir / f"simple_rag_demo_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

# Configure loguru for detailed logging
log.remove()  # Remove default handler
log.add(sys.stderr, level="INFO", format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}")
log.add(log_file, level="DEBUG", format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level} | {name}:{function}:{line} | {message}")

log.info("=== SIMPLE RAG DEMO SESSION STARTED ===")
log.info(f"Log file: {log_file}")
log.info(f"Working directory: {Path.cwd()}")

def load_transcription_text() -> str:
    """Load the transcription text from our created file."""
    log.debug("Starting transcription loading process")
    
    # Try local data first, fallback to main data
    local_transcript = Path("data/audio/transcript.txt")
    main_transcript = Path(r"../../data/audio/–í –º–µ—Å—è—Ü —Ç—ã –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—à—å –±–æ–ª—å—à–µ 1–º–ª–Ω —Ä—É–±–ª–µ–πÔºü –ó–≤–µ–∑–¥–∞ ÔºÇ–†–µ—É—Ç–æ–≤ –¢–íÔºÇ —É –î—É–¥—è.real_transcript.txt")
    
    transcript_file = local_transcript if local_transcript.exists() else main_transcript
    log.info(f"Using transcript file: {transcript_file}")
    
    bash(f"ls -la {transcript_file.parent}")
    
    if not transcript_file.exists():
        log.error(f"Transcript file not found: {transcript_file}")
        raise FileNotFoundError(f"‚ùå Transcript file not found: {transcript_file}")

    try:
        log.debug(f"Reading transcript file: {transcript_file}")
        with transcript_file.open("r", encoding="utf-8") as f:
            content = f.read()
        
        log.debug(f"Raw content length: {len(content)} characters")
        
        # Extract just the text from timestamped segments
        lines = content.split('\n')
        text_segments = []
        
        log.debug(f"Processing {len(lines)} lines")
        for i, line in enumerate(lines):
            line = line.strip()
            if line.startswith("[") and "]" in line:
                # Extract text after timestamp
                text_part = line.split("]", 1)[1].strip()
                if text_part:
                    text_segments.append(text_part)
                    log.debug(f"Line {i}: extracted segment '{text_part[:50]}...'")
        
        full_text = " ".join(text_segments)
        log.info(f"Successfully loaded transcription: {len(text_segments)} segments, {len(full_text)} characters")
        print(f"‚úÖ Loaded transcription: {len(text_segments)} segments, {len(full_text)} characters")
        return full_text
        
    except Exception as e:
        log.error(f"Failed to load transcription: {e}")
        print(f"‚ùå Failed to load transcription: {e}")
        return ""

def create_simple_rag_qa():
    """Create a simple RAG Q&A system using our project structure."""
    
    log.info("Starting RAG Q&A system creation")
    print("üîß Creating simple RAG Q&A system...")
    
    # Load transcription
    log.debug("Loading transcription text")
    transcript_text = load_transcription_text()
    if not transcript_text:
        log.error("No transcript text loaded, aborting RAG creation")
        return None
    
    log.info(f"Transcript loaded successfully: {len(transcript_text)} characters")
    
    # Test if our project's RAG components are available
    try:
        log.debug("Attempting to import project components")
        # Try to use project components
        from llm_rag_yt.config.settings import get_config
        from llm_rag_yt.text.processor import TextProcessor
        
        log.info("Project components imported successfully")
        print("‚úÖ Project components available")
        
        # Get configuration
        log.debug("Loading configuration")
        config = get_config()
        log.info(f"Config loaded - chunk_size: {config.chunk_size}, chunk_overlap: {config.chunk_overlap}")
        
        # Create text processor for chunking
        log.debug("Creating TextProcessor instance")
        text_processor = TextProcessor()
        
        # Process the transcript
        log.info("Starting transcript processing")
        print("üìù Processing transcript into chunks...")
        
        log.debug("Normalizing transcript text")
        normalized_text = text_processor.normalize_text(transcript_text)
        log.debug(f"Normalized text length: {len(normalized_text)} characters")
        
        log.debug(f"Splitting into chunks with size={config.chunk_size}, overlap={config.chunk_overlap}")
        processed_chunks = text_processor.split_into_chunks(
            normalized_text,
            chunk_size=config.chunk_size,
            overlap=config.chunk_overlap
        )
        
        log.info(f"Successfully created {len(processed_chunks)} text chunks")
        print(f"‚úÖ Created {len(processed_chunks)} text chunks")
        
        # Create a simple in-memory RAG system
        log.debug("Creating RAG data structure")
        rag_data = {
            "chunks": processed_chunks,
            "full_text": transcript_text,
            "metadata": {
                "source": "YouTube Shorts",
                "title": "–í –º–µ—Å—è—Ü —Ç—ã –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—à—å –±–æ–ª—å—à–µ 1–º–ª–Ω —Ä—É–±–ª–µ–πÔºü –ó–≤–µ–∑–¥–∞ ÔºÇ–†–µ—É—Ç–æ–≤ –¢–íÔºÇ —É –î—É–¥—è",
                "language": "ru",
                "chunk_count": len(processed_chunks),
                "created_at": datetime.now().isoformat(),
                "transcript_length": len(transcript_text)
            }
        }
        
        log.info("RAG data structure created successfully")
        log.debug(f"RAG data: {len(rag_data['chunks'])} chunks, metadata: {rag_data['metadata']}")
        return rag_data
        
    except ImportError as e:
        log.warning(f"Project components not available: {e}")
        log.info("Falling back to simple chunking")
        print(f"‚ùå Project components not available: {e}")
        
        # Fallback: simple chunking
        print("üîÑ Using fallback simple chunking...")
        words = transcript_text.split()
        chunk_size = 50  # words per chunk
        chunks = []
        
        log.debug(f"Splitting {len(words)} words into chunks of {chunk_size}")
        for i in range(0, len(words), chunk_size):
            chunk = " ".join(words[i:i + chunk_size])
            chunks.append(chunk)
            log.debug(f"Created chunk {len(chunks)}: '{chunk[:50]}...'")
        
        log.info(f"Created {len(chunks)} simple chunks using fallback method")
        print(f"‚úÖ Created {len(chunks)} simple chunks")
        
        rag_data = {
            "chunks": chunks,
            "full_text": transcript_text,
            "metadata": {
                "source": "YouTube Shorts",
                "title": "–í –º–µ—Å—è—Ü —Ç—ã –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—à—å –±–æ–ª—å—à–µ 1–º–ª–Ω —Ä—É–±–ª–µ–πÔºü –ó–≤–µ–∑–¥–∞ ÔºÇ–†–µ—É—Ç–æ–≤ –¢–íÔºÇ —É –î—É–¥—è",
                "language": "ru",
                "chunk_count": len(chunks),
                "created_at": datetime.now().isoformat(),
                "transcript_length": len(transcript_text),
                "method": "fallback_chunking"
            }
        }
        
        return rag_data

def simple_search(query: str, rag_data: Dict[str, Any]) -> List[str]:
    """Simple keyword-based search in chunks."""
    
    log.debug(f"Starting search for query: '{query}'")
    query_words = set(query.lower().split())
    log.debug(f"Query words: {query_words}")
    
    # Score chunks by keyword overlap
    chunk_scores = []
    log.debug(f"Searching through {len(rag_data['chunks'])} chunks")
    
    for i, chunk in enumerate(rag_data["chunks"]):
        chunk_words = set(chunk.lower().split())
        overlap = len(query_words.intersection(chunk_words))
        if overlap > 0:
            chunk_scores.append((overlap, i, chunk))
            log.debug(f"Chunk {i}: {overlap} word overlap - '{chunk[:50]}...'")
    
    # Sort by score and return top matches
    chunk_scores.sort(reverse=True, key=lambda x: x[0])
    log.debug(f"Found {len(chunk_scores)} matching chunks, returning top 3")
    
    # Return top 3 chunks
    top_chunks = []
    for score, idx, chunk in chunk_scores[:3]:
        top_chunks.append(chunk)
        log.debug(f"Top chunk (score {score}): '{chunk[:50]}...'")
    
    log.info(f"Search completed: {len(top_chunks)} relevant chunks found for query '{query}'")
    return top_chunks

def generate_simple_answer(question: str, context_chunks: List[str], full_text: str) -> str:
    """Generate a simple answer based on context."""
    
    log.debug(f"Generating answer for question: '{question}'")
    log.debug(f"Context chunks available: {len(context_chunks)}")
    
    if not context_chunks:
        log.warning("No context chunks available for answer generation")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å."
    
    # Simple keyword-based answer generation
    context = " ".join(context_chunks)
    log.debug(f"Combined context length: {len(context)} characters")
    
    # Common question patterns
    if any(word in question.lower() for word in ["—Å–∫–æ–ª—å–∫–æ", "–∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç", "–∑–∞—Ä–∞–±–æ—Ç–æ–∫", "–¥–µ–Ω—å–≥–∏", "—Ä—É–±–ª–µ–π"]):
        log.debug("Detected earnings-related question")
        if "–º–∏–ª–ª–∏–æ–Ω" in context.lower():
            answer = "–ü–æ —Å–ª–æ–≤–∞–º –≥–µ—Ä–æ—è –≤–∏–¥–µ–æ, –æ–Ω –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–æ–ª—å—à–µ –º–∏–ª–ª–∏–æ–Ω–∞ —Ä—É–±–ª–µ–π –≤ –º–µ—Å—è—Ü. –û–Ω –æ–±—ä—è—Å–Ω—è–µ—Ç, —á—Ç–æ –∑–∞–Ω–∏–º–∞—Ç—å—Å—è –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ - –∞–∫—Ç–µ—Ä—Å—Ç–≤–æ, —Å—Ü–µ–Ω–∞—Ä–Ω–æ–µ –¥–µ–ª–æ, –∫–æ–Ω—Ü–µ—Ä—Ç—ã, –±–ª–æ–≥–∏–Ω–≥, –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ."
            log.info(f"Generated earnings answer: '{answer[:50]}...'")
            return answer
    
    if any(word in question.lower() for word in ["—á—Ç–æ", "—á–µ–º", "—Ä–∞–±–æ—Ç–∞", "–¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å"]):
        log.debug("Detected work/activity-related question")
        if "–∞–∫—Ç–µ—Ä" in context.lower() or "—Å—Ü–µ–Ω–∞—Ä–∏—Å—Ç" in context.lower():
            answer = "–ì–µ—Ä–æ–π –≤–∏–¥–µ–æ —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –æ–Ω —Ç—Ä—É–¥–æ–≥–æ–ª–∏–∫ –∏ –∑–∞–Ω–∏–º–∞–µ—Ç—Å—è –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º —Ä–∞–∑–Ω—ã—Ö –≤–∏–¥–æ–≤ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: –∞–∫—Ç–µ—Ä—Å—Ç–≤–æ, —Å—Ü–µ–Ω–∞—Ä–Ω–æ–µ –¥–µ–ª–æ, –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π, –∫–æ–Ω—Ü–µ—Ä—Ç—ã, –±–ª–æ–≥–∏–Ω–≥, –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∏ –¥—Ä—É–≥–æ–µ."
            log.info(f"Generated activity answer: '{answer[:50]}...'")
            return answer
    
    if any(word in question.lower() for word in ["–∫–∞–∫", "–∫–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º"]):
        log.debug("Detected how/method-related question")
        answer = "–ì–µ—Ä–æ–π –≤–∏–¥–µ–æ –æ–±—ä—è—Å–Ω—è–µ—Ç, —á—Ç–æ —Å–∞–º–∞—è –±–æ–ª—å—à–∞—è –ø—Ä–æ–±–ª–µ–º–∞ - —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å, —á–µ–º –∏–º–µ–Ω–Ω–æ –æ–Ω –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç –æ—á–µ–Ω—å –º–Ω–æ–≥–æ –≤—Å–µ–≥–æ. –û–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ –∞–∫—Ç–µ—Ä, —Å—Ü–µ–Ω–∞—Ä–∏—Å—Ç, –ø—Ä–æ–≤–æ–¥–∏—Ç –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è, –≤—ã—Å—Ç—É–ø–∞–µ—Ç –Ω–∞ –∫–æ–Ω—Ü–µ—Ä—Ç–∞—Ö, –≤–µ–¥–µ—Ç –±–ª–æ–≥ –∏ –∑–∞–Ω–∏–º–∞–µ—Ç—Å—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è–º–∏."
        log.info(f"Generated method answer: '{answer[:50]}...'")
        return answer
    
    # Default response with context
    log.debug("Using default answer template with context")
    answer = f"–ù–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤–∏–¥–µ–æ: {context[:200]}..."
    log.info(f"Generated default answer: '{answer[:50]}...'")
    return answer

def interactive_simple_qa(rag_data: Dict[str, Any]):
    """Run simple interactive Q&A session."""
    
    log.info("Starting interactive Q&A session")
    log.debug(f"RAG data contains {len(rag_data['chunks'])} chunks")
    
    print("\n" + "="*60)
    print("ü§ñ –ü–†–û–°–¢–ê–Ø –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–ê–Ø –°–ï–°–°–ò–Ø –í–û–ü–†–û–°–û–í –ò –û–¢–í–ï–¢–û–í")
    print("="*60)
    print(f"üìπ –í–∏–¥–µ–æ: {rag_data['metadata']['title']}")
    print(f"üìä –î–∞–Ω–Ω—ã–µ: {rag_data['metadata']['chunk_count']} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Ç–µ–∫—Å—Ç–∞")
    print("üí° –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏ –≤–∏–¥–µ–æ")
    print("‚å®Ô∏è –ù–∞–ø–∏—à–∏—Ç–µ 'quit' –∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞")
    print("="*60)
    
    while True:
        try:
            log.debug("Waiting for user input...")
            question = input("\nü§î –í–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()
            
            if question.lower() in ['quit', 'exit', '–≤—ã—Ö–æ–¥', 'q']:
                log.info("User requested to quit interactive session")
                print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                break
            
            if not question:
                log.debug("Empty question received")
                print("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å")
                continue
            
            log.info(f"Processing user question: '{question}'")
            print(f"\nüîç –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è: '{question}'")
            
            # Search for relevant chunks
            log.debug("Starting chunk search")
            relevant_chunks = simple_search(question, rag_data)
            
            # Generate answer
            log.debug("Starting answer generation")
            answer = generate_simple_answer(question, relevant_chunks, rag_data["full_text"])
            
            log.info(f"Generated answer for question '{question}': '{answer[:50]}...'")
            
            print(f"\nüí¨ –û–¢–í–ï–¢:")
            print("-" * 40)
            print(answer)
            
            if relevant_chunks:
                log.debug(f"Displaying {len(relevant_chunks)} relevant chunks")
                print(f"\nüìö –ù–ê–ô–î–ï–ù–ù–´–ï –§–†–ê–ì–ú–ï–ù–¢–´ ({len(relevant_chunks)}):")
                print("-" * 40)
                for i, chunk in enumerate(relevant_chunks, 1):
                    preview = chunk[:100] + "..." if len(chunk) > 100 else chunk
                    print(f"{i}. {preview}")
                    log.debug(f"Chunk {i}: '{chunk[:50]}...'")
            
        except KeyboardInterrupt:
            log.info("Interactive session interrupted by user (Ctrl+C)")
            print("\n\nüëã –°–µ—Å—Å–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            break
        except Exception as e:
            log.error(f"Error in interactive session: {e}")
            print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")

@log.catch
def main():
    """Main function for simple RAG demo."""
    log.info("=== MAIN FUNCTION STARTED ===")
    log.info(f"Script path: {Path(__file__)}")
    log.info(f"Current working directory: {Path.cwd()}")
    log.info(f"Python path: {sys.path[:3]}...")  # First 3 entries
    
    print("üöÄ –ü–†–û–°–¢–ê–Ø RAG DEMO - –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ò Q&A")
    print("="*50)
    
    # Create simple RAG data
    log.info("Creating RAG Q&A system")
    rag_data = create_simple_rag_qa()
    if not rag_data:
        log.error("Failed to create RAG data")
        print("‚ùå Failed to create RAG data")
        return 1
    
    log.info("RAG data created successfully")
    log.debug(f"RAG metadata: {rag_data['metadata']}")
    
    # Show some examples
    print("\nüß™ –ü–†–ò–ú–ï–†–´ –í–û–ü–†–û–°–û–í:")
    example_questions = [
        "–°–∫–æ–ª—å–∫–æ –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥–µ—Ä–æ–π –≤–∏–¥–µ–æ?",
        "–ß–µ–º –∑–∞–Ω–∏–º–∞–µ—Ç—Å—è –≥–µ—Ä–æ–π?",
        "–ö–∞–∫ –æ–Ω –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–µ–Ω—å–≥–∏?",
        "–ß—Ç–æ –æ–Ω –≥–æ–≤–æ—Ä–∏—Ç –æ —Ä–∞–±–æ—Ç–µ?"
    ]
    
    for q in example_questions:
        print(f"  ‚Ä¢ {q}")
    
    # Test one example
    print(f"\nüß™ –¢–ï–°–¢–û–í–´–ô –í–û–ü–†–û–°:")
    test_question = "–°–∫–æ–ª—å–∫–æ –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥–µ—Ä–æ–π –≤–∏–¥–µ–æ?"
    print(f"–í–æ–ø—Ä–æ—Å: {test_question}")
    
    log.info(f"Running test question: '{test_question}'")
    relevant_chunks = simple_search(test_question, rag_data)
    answer = generate_simple_answer(test_question, relevant_chunks, rag_data["full_text"])
    print(f"–û—Ç–≤–µ—Ç: {answer}")
    
    log.info(f"Test question completed successfully")
    
    # Start interactive session
    log.info("Starting interactive Q&A session")
    interactive_simple_qa(rag_data)
    
    log.info("=== MAIN FUNCTION COMPLETED ===")
    return 0

if __name__ == "__main__":
    sys.exit(main())