#!/usr/bin/env python3
"""Complete RAG pipeline demo: load transcription data and create interactive Q&A."""

import os
import sys
from pathlib import Path
from typing import List, Dict, Any

# Add src to Python path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

def install_required_packages():
    """Install packages needed for RAG demo."""
    packages_to_check = [
        ("openai", "openai"),
        ("chromadb", "chromadb"), 
        ("sentence_transformers", "sentence-transformers"),
    ]
    
    missing_packages = []
    for import_name, pip_name in packages_to_check:
        try:
            __import__(import_name)
            print(f"‚úÖ {import_name} available")
        except ImportError:
            missing_packages.append(pip_name)
    
    if missing_packages:
        print(f"üì¶ Installing missing packages: {missing_packages}")
        for package in missing_packages:
            result = os.system(f"pip install {package}")
            if result != 0:
                print(f"‚ùå Failed to install {package}")
                return False
        print("‚úÖ All packages installed")
    
    return True

def load_transcription_data() -> List[Dict[str, Any]]:
    """Load transcription data from our test files."""
    
    # Load the real transcription we created
    transcript_file = Path("data/audio/–í –º–µ—Å—è—Ü —Ç—ã –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—à—å –±–æ–ª—å—à–µ 1–º–ª–Ω —Ä—É–±–ª–µ–πÔºü –ó–≤–µ–∑–¥–∞ ÔºÇ–†–µ—É—Ç–æ–≤ –¢–íÔºÇ —É –î—É–¥—è.real_transcript.txt")
    
    if not transcript_file.exists():
        print(f"‚ùå Transcript file not found: {transcript_file}")
        return []
    
    print(f"üìñ Loading transcription: {transcript_file.name}")
    
    try:
        with transcript_file.open("r", encoding="utf-8") as f:
            lines = f.readlines()
        
        # Parse the transcript format: [start-end] text
        documents = []
        metadata = {}
        
        for line in lines:
            line = line.strip()
            if line.startswith("#"):
                # Parse metadata
                if "Language:" in line:
                    parts = line.split("Language:")
                    if len(parts) > 1:
                        lang_info = parts[1].split(",")[0].strip()
                        metadata["language"] = lang_info
                elif "Duration:" in line:
                    duration_part = line.split("Duration:")[1].split("s")[0].strip()
                    try:
                        metadata["duration"] = float(duration_part)
                    except:
                        pass
                continue
            
            if line.startswith("[") and "]" in line:
                # Parse timestamped segment: [start-end] text
                try:
                    timestamp_part = line.split("]")[0] + "]"
                    text_part = line.split("]", 1)[1].strip()
                    
                    # Extract start and end times
                    times = timestamp_part[1:-1]  # Remove brackets
                    start_str, end_str = times.split("-")
                    start_time = float(start_str)
                    end_time = float(end_str)
                    
                    if text_part:  # Only add non-empty segments
                        doc = {
                            "text": text_part,
                            "metadata": {
                                "source": "youtube_shorts",
                                "video_title": "–í –º–µ—Å—è—Ü —Ç—ã –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—à—å –±–æ–ª—å—à–µ 1–º–ª–Ω —Ä—É–±–ª–µ–πÔºü –ó–≤–µ–∑–¥–∞ ÔºÇ–†–µ—É—Ç–æ–≤ –¢–íÔºÇ —É –î—É–¥—è",
                                "start_time": start_time,
                                "end_time": end_time,
                                "duration": end_time - start_time,
                                "language": metadata.get("language", "ru"),
                                "segment_id": len(documents)
                            }
                        }
                        documents.append(doc)
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è Failed to parse line: {line[:50]}... Error: {e}")
                    continue
        
        print(f"‚úÖ Loaded {len(documents)} text segments")
        
        # Add full text as a single document as well
        if documents:
            full_text = " ".join([doc["text"] for doc in documents])
            full_doc = {
                "text": full_text,
                "metadata": {
                    "source": "youtube_shorts",
                    "video_title": "–í –º–µ—Å—è—Ü —Ç—ã –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—à—å –±–æ–ª—å—à–µ 1–º–ª–Ω —Ä—É–±–ª–µ–πÔºü –ó–≤–µ–∑–¥–∞ ÔºÇ–†–µ—É—Ç–æ–≤ –¢–íÔºÇ —É –î—É–¥—è",
                    "start_time": 0.0,
                    "end_time": metadata.get("duration", 44.8),
                    "duration": metadata.get("duration", 44.8),
                    "language": metadata.get("language", "ru"),
                    "segment_id": "full_text"
                }
            }
            documents.append(full_doc)
            print(f"‚úÖ Added full text document ({len(full_text)} characters)")
        
        return documents
        
    except Exception as e:
        print(f"‚ùå Failed to load transcription: {e}")
        return []

def setup_rag_components():
    """Set up RAG components: embeddings, vector store, LLM."""
    
    print("üîß Setting up RAG components...")
    
    # Initialize embeddings
    try:
        from sentence_transformers import SentenceTransformer
        print("üìä Loading embedding model...")
        embedding_model = SentenceTransformer('intfloat/multilingual-e5-large-instruct')
        print("‚úÖ Embedding model loaded")
    except Exception as e:
        print(f"‚ùå Failed to load embedding model: {e}")
        return None, None, None
    
    # Initialize vector store
    try:
        import chromadb
        from chromadb.config import Settings
        
        print("üóÑÔ∏è Setting up ChromaDB...")
        
        # Create client with persistent storage
        chroma_client = chromadb.PersistentClient(
            path=str(Path("data/chroma_db").absolute()),
            settings=Settings(anonymized_telemetry=False)
        )
        
        # Get or create collection
        collection_name = "youtube_rag_demo"
        try:
            collection = chroma_client.get_collection(collection_name)
            print(f"‚úÖ Using existing collection: {collection_name}")
        except:
            collection = chroma_client.create_collection(
                name=collection_name,
                metadata={"description": "YouTube RAG demo collection"}
            )
            print(f"‚úÖ Created new collection: {collection_name}")
        
    except Exception as e:
        print(f"‚ùå Failed to setup ChromaDB: {e}")
        return None, None, None
    
    # Initialize OpenAI client
    try:
        import openai
        from dotenv import load_dotenv
        
        # Load environment variables
        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")
        
        if not api_key:
            print("‚ùå OPENAI_API_KEY not found in environment")
            return None, None, None
        
        openai_client = openai.OpenAI(api_key=api_key)
        print("‚úÖ OpenAI client initialized")
        
    except Exception as e:
        print(f"‚ùå Failed to setup OpenAI: {e}")
        return None, None, None
    
    return embedding_model, collection, openai_client

def load_documents_to_rag(documents: List[Dict[str, Any]], embedding_model, collection):
    """Load documents into RAG vector database."""
    
    if not documents:
        print("‚ùå No documents to load")
        return False
    
    print(f"üì• Loading {len(documents)} documents into RAG database...")
    
    try:
        # Check if collection already has documents
        existing_count = collection.count()
        if existing_count > 0:
            print(f"‚ÑπÔ∏è Collection already has {existing_count} documents")
            user_input = input("ü§î Clear existing data and reload? (y/n): ").lower().strip()
            if user_input == 'y':
                collection.delete(where={})
                print("üóëÔ∏è Cleared existing data")
            else:
                print("üìö Using existing data")
                return True
        
        # Prepare data for ChromaDB
        texts = []
        metadatas = []
        ids = []
        
        for i, doc in enumerate(documents):
            texts.append(doc["text"])
            metadatas.append(doc["metadata"])
            ids.append(f"doc_{i}")
        
        # Generate embeddings
        print("üîÑ Generating embeddings...")
        embeddings = embedding_model.encode(texts, convert_to_tensor=False)
        embeddings_list = [emb.tolist() for emb in embeddings]
        
        # Add to collection
        print("üíæ Adding documents to vector store...")
        collection.add(
            documents=texts,
            metadatas=metadatas,
            embeddings=embeddings_list,
            ids=ids
        )
        
        final_count = collection.count()
        print(f"‚úÖ Successfully loaded {final_count} documents into RAG database")
        return True
        
    except Exception as e:
        print(f"‚ùå Failed to load documents: {e}")
        import traceback
        traceback.print_exc()
        return False

def query_rag(question: str, embedding_model, collection, openai_client, top_k: int = 3) -> Dict[str, Any]:
    """Query the RAG system with a question."""
    
    try:
        # Generate query embedding
        query_embedding = embedding_model.encode([question], convert_to_tensor=False)[0].tolist()
        
        # Search vector database
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["documents", "metadatas", "distances"]
        )
        
        if not results["documents"][0]:
            return {
                "question": question,
                "answer": "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.",
                "sources": []
            }
        
        # Prepare context from retrieved documents
        context_parts = []
        sources = []
        
        for i, (doc, metadata, distance) in enumerate(zip(
            results["documents"][0],
            results["metadatas"][0], 
            results["distances"][0]
        )):
            context_parts.append(f"[–°–µ–≥–º–µ–Ω—Ç {i+1}]: {doc}")
            
            source_info = {
                "segment_id": metadata.get("segment_id", i),
                "start_time": metadata.get("start_time", 0),
                "end_time": metadata.get("end_time", 0),
                "distance": distance,
                "text": doc[:100] + "..." if len(doc) > 100 else doc
            }
            sources.append(source_info)
        
        context = "\n\n".join(context_parts)
        
        # Generate answer using OpenAI
        system_prompt = """–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤–∏–¥–µ–æ —Å YouTube. 
–í–∏–¥–µ–æ: "–í –º–µ—Å—è—Ü —Ç—ã –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—à—å –±–æ–ª—å—à–µ 1–º–ª–Ω —Ä—É–±–ª–µ–πÔºü –ó–≤–µ–∑–¥–∞ ÔºÇ–†–µ—É—Ç–æ–≤ –¢–íÔºÇ —É –î—É–¥—è"

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:
1. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
2. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
3. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏
4. –ë—É–¥—å —Ç–æ—á–Ω—ã–º –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º
5. –°—Å—ã–ª–∞–π—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã –∏–∑ –≤–∏–¥–µ–æ –∫–æ–≥–¥–∞ —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ"""

        user_prompt = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –≤–∏–¥–µ–æ:
{context}

–í–æ–ø—Ä–æ—Å: {question}

–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."""

        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )
        
        answer = response.choices[0].message.content
        
        return {
            "question": question,
            "answer": answer,
            "sources": sources,
            "context": context
        }
        
    except Exception as e:
        print(f"‚ùå Failed to query RAG: {e}")
        return {
            "question": question,
            "answer": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {e}",
            "sources": []
        }

def interactive_qa_session(embedding_model, collection, openai_client):
    """Run interactive Q&A session."""
    
    print("\n" + "="*60)
    print("ü§ñ –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–ê–Ø –°–ï–°–°–ò–Ø –í–û–ü–†–û–°–û–í –ò –û–¢–í–ï–¢–û–í")
    print("="*60)
    print("üìπ –í–∏–¥–µ–æ: '–í –º–µ—Å—è—Ü —Ç—ã –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—à—å –±–æ–ª—å—à–µ 1–º–ª–Ω —Ä—É–±–ª–µ–πÔºü –ó–≤–µ–∑–¥–∞ ÔºÇ–†–µ—É—Ç–æ–≤ –¢–íÔºÇ —É –î—É–¥—è'")
    print("üí° –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏ –≤–∏–¥–µ–æ")
    print("‚å®Ô∏è –ù–∞–ø–∏—à–∏—Ç–µ 'quit' –∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞")
    print("="*60)
    
    while True:
        try:
            question = input("\nü§î –í–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()
            
            if question.lower() in ['quit', 'exit', '–≤—ã—Ö–æ–¥', 'q']:
                print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                break
            
            if not question:
                print("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å")
                continue
            
            print(f"\nüîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–æ–ø—Ä–æ—Å: '{question}'")
            print("‚è≥ –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏...")
            
            result = query_rag(question, embedding_model, collection, openai_client)
            
            print(f"\nüí¨ –û–¢–í–ï–¢:")
            print("-" * 40)
            print(result["answer"])
            
            if result["sources"]:
                print(f"\nüìö –ò–°–¢–û–ß–ù–ò–ö–ò ({len(result['sources'])} —Å–µ–≥–º–µ–Ω—Ç–æ–≤):")
                print("-" * 40)
                for i, source in enumerate(result["sources"], 1):
                    start_time = source.get("start_time", 0)
                    end_time = source.get("end_time", 0)
                    print(f"{i}. [{start_time:.1f}s-{end_time:.1f}s]: {source['text']}")
            
        except KeyboardInterrupt:
            print("\n\nüëã –°–µ—Å—Å–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            break
        except Exception as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")

def main():
    """Main RAG demo function."""
    print("üöÄ RAG PIPELINE DEMO - –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ò –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô Q&A")
    print("="*70)
    
    # Install required packages
    if not install_required_packages():
        return 1
    
    # Load transcription data
    documents = load_transcription_data()
    if not documents:
        return 1
    
    # Setup RAG components
    embedding_model, collection, openai_client = setup_rag_components()
    if not all([embedding_model, collection, openai_client]):
        return 1
    
    # Load documents into RAG
    if not load_documents_to_rag(documents, embedding_model, collection):
        return 1
    
    # Test the system with a sample query
    print("\nüß™ –¢–ï–°–¢–û–í–´–ô –ó–ê–ü–†–û–°")
    print("-" * 30)
    test_question = "–°–∫–æ–ª—å–∫–æ –∑–∞—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥–µ—Ä–æ–π –≤–∏–¥–µ–æ?"
    print(f"–í–æ–ø—Ä–æ—Å: {test_question}")
    
    test_result = query_rag(test_question, embedding_model, collection, openai_client)
    print(f"–û—Ç–≤–µ—Ç: {test_result['answer']}")
    
    # Start interactive session
    interactive_qa_session(embedding_model, collection, openai_client)
    
    return 0

if __name__ == "__main__":
    sys.exit(main())